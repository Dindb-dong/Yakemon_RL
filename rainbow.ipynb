{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch numpy matplotlib\n",
    "#!pip install nest-asyncio\n",
    "#!pip install \"ray[rllib]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wogn2\\AppData\\Roaming\\Python\\Python312\\site-packages\\ray\\rllib\\utils\\framework.py:186: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import ray\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# 환경 관련 import\n",
    "from env.battle_env import YakemonEnv\n",
    "\n",
    "# 유틸리티 관련 import\n",
    "from utils.battle_logics.create_battle_pokemon import create_battle_pokemon\n",
    "\n",
    "# RL 관련 import\n",
    "from RL.reward_calculator import calculate_reward\n",
    "from RL.get_state_vector import get_state\n",
    "\n",
    "# 데이터 관련 import\n",
    "from p_data.move_data import move_data\n",
    "from p_data.ability_data import ability_data\n",
    "from p_data.mock_pokemon import create_mock_pokemon_list\n",
    "\n",
    "# 컨텍스트 관련 import\n",
    "from context.battle_store import store\n",
    "from context.duration_store import duration_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU 가용성 확인\n",
    "num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "print(f\"Available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수 초기화\n",
    "battle_store = store\n",
    "duration_store = duration_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 10:48:18,794\tERROR services.py:1362 -- Failed to start the dashboard , return code 3221226505\n",
      "2025-05-14 10:48:18,796\tERROR services.py:1387 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-05-14 10:48:18,813\tERROR services.py:1431 -- \n",
      "The last 20 lines of C:\\Users\\wogn2\\AppData\\Local\\Temp\\ray\\session_2025-05-14_10-48-16_912724_2644\\logs\\dashboard.log (it contains the error message from the dashboard): \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\wogn2\\AppData\\Roaming\\Python\\Python312\\site-packages\\ray\\dashboard\\dashboard.py\", line 247, in <module>\n",
      "    logging_utils.redirect_stdout_stderr_if_needed(\n",
      "  File \"C:\\Users\\wogn2\\AppData\\Roaming\\Python\\Python312\\site-packages\\ray\\_private\\logging_utils.py\", line 48, in redirect_stdout_stderr_if_needed\n",
      "    sys.stderr = open_log(stderr_fileno, unbuffered=True, closefd=False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wogn2\\AppData\\Roaming\\Python\\Python312\\site-packages\\ray\\_private\\utils.py\", line 446, in open_log\n",
      "    stream = open(path, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 6] 핸들이 잘못되었습니다\n",
      "\n",
      "\n",
      "2025-05-14 10:48:19,003\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Ray 초기화\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 09:06:35,422\tERROR services.py:1362 -- Failed to start the dashboard , return code 3221226505\n",
      "2025-05-14 09:06:35,424\tERROR services.py:1387 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-05-14 09:06:35,438\tERROR services.py:1397 -- Couldn't read dashboard.log file. Error: 'utf-8' codec can't decode byte 0xc7 in position 22: invalid continuation byte. It means the dashboard is broken even before it initializes the logger (mostly dependency issues). Reading the dashboard.err file which contains stdout/stderr.\n",
      "2025-05-14 09:06:35,441\tERROR services.py:1431 -- \n",
      "The last 20 lines of C:\\Users\\wogn2\\AppData\\Local\\Temp\\ray\\session_2025-05-14_09-06-33_457382_17996\\logs\\dashboard.err (it contains the error message from the dashboard): \n",
      "2025-05-14 09:06:35,619\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Rainbow DQN 설정\n",
    "config = (\n",
    "    DQNConfig()\n",
    "    .environment(\n",
    "        YakemonEnv,\n",
    "        env_config={}\n",
    "    )\n",
    "    .training(\n",
    "        # Rainbow DQN 핵심 기능들\n",
    "        double_q=True,  # Double DQN\n",
    "        dueling=True,   # Dueling DQN\n",
    "        n_step=3,       # N-step learning\n",
    "        num_atoms=51,   # Distributional DQN\n",
    "        v_min=-10.0,    # Distributional DQN value range\n",
    "        v_max=10.0,     # Distributional DQN value range\n",
    "        noisy=True,     # Noisy Networks\n",
    "        sigma0=0.5,     # Noisy Networks 초기 파라미터\n",
    "        \n",
    "        # Replay Buffer 설정\n",
    "        replay_buffer_config={\n",
    "            \"type\": \"PrioritizedEpisodeReplayBuffer\",\n",
    "            \"capacity\": 100000,\n",
    "            \"alpha\": 0.6,  # Prioritized Experience Replay\n",
    "            \"beta\": 0.4,   # Importance Sampling\n",
    "        },\n",
    "        \n",
    "        # 학습 관련 설정\n",
    "        lr=0.00025,\n",
    "        train_batch_size=32,\n",
    "        gamma=0.99,\n",
    "        target_network_update_freq=1000,\n",
    "        num_steps_sampled_before_learning_starts=1000,\n",
    "        td_error_loss_fn=\"huber\",  # Huber loss for stability\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(num_rollout_workers=0)\n",
    "    .debugging(log_level=\"ERROR\")\n",
    "    .resources(num_gpus=num_gpus)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rainbow import test_agent\n",
    "from rainbow import train_agent\n",
    "from datetime import datetime\n",
    "from rainbow import plot_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter에서 중첩된 이벤트 루프 허용\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    # 결과 저장 디렉토리 설정\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join('results', f'training_{timestamp}')\n",
    "    models_dir = os.path.join('models', f'training_{timestamp}')\n",
    "    \n",
    "    # 환경 초기화\n",
    "    env = YakemonEnv()\n",
    "    \n",
    "    # Rainbow DQN 알고리즘 생성\n",
    "    algo = config.build()\n",
    "    \n",
    "    print(\"Starting Rainbow DQN training...\")\n",
    "    print(f\"Results will be saved in: {results_dir}\")\n",
    "    print(f\"Models will be saved in: {models_dir}\")\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(pretty_print(config.to_dict()))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Rainbow DQN 에이전트 학습\n",
    "    rainbow_rewards = asyncio.run(train_agent(\n",
    "        env=env,\n",
    "        algo=algo,\n",
    "        num_episodes=1000,\n",
    "        save_path=models_dir,\n",
    "        agent_name='rainbow'\n",
    "    ))\n",
    "    \n",
    "    # 학습 결과 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(rainbow_rewards, label='Average Reward', color='blue', alpha=0.6)\n",
    "    plt.title('Rainbow DQN Training Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(results_dir, 'rainbow_rewards.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Results saved in: {results_dir}\")\n",
    "    print(f\"Models saved in: {models_dir}\")\n",
    "    \n",
    "    # 학습된 에이전트 테스트\n",
    "    print(\"\\nStarting test phase...\")\n",
    "    test_results = asyncio.run(test_agent(\n",
    "        env=env,\n",
    "        algo=algo,\n",
    "        num_episodes=100\n",
    "    ))\n",
    "    \n",
    "    # 테스트 결과 저장\n",
    "    test_stats = {\n",
    "        'avg_reward': test_results[0],\n",
    "        'std_reward': test_results[1],\n",
    "        'avg_steps': test_results[2],\n",
    "        'victories': test_results[3],\n",
    "        'win_rate': test_results[4]\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(results_dir, 'test_results.json'), 'w') as f:\n",
    "        json.dump(test_stats, f, indent=4)\n",
    "    \n",
    "    with open(os.path.join(results_dir, 'test_results.txt'), 'w') as f:\n",
    "        f.write(\"Test Results\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Average Reward: {test_stats['avg_reward']:.4f} ± {test_stats['std_reward']:.4f}\\n\")\n",
    "        f.write(f\"Average Steps: {test_stats['avg_steps']:.2f}\\n\")\n",
    "        f.write(f\"Victories: {test_stats['victories']}/100 (Win Rate: {test_stats['win_rate']:.1f}%)\\n\")\n",
    "    \n",
    "    print(\"\\nTest completed!\")\n",
    "    print(f\"Test results saved in: {results_dir}\")\n",
    "    \n",
    "    # Ray 종료\n",
    "    ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
