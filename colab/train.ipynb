{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minwoo/miniforge3/envs/yakemon/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -7.09, Win Rate: 0.00%\n",
      "Episode 10, Total Reward: -9.05, Win Rate: 0.00%\n",
      "Episode 20, Total Reward: -8.62, Win Rate: 0.00%\n",
      "Episode 30, Total Reward: -11.68, Win Rate: 0.00%\n",
      "Episode 40, Total Reward: -10.06, Win Rate: 0.00%\n",
      "Episode 50, Total Reward: -8.34, Win Rate: 0.00%\n",
      "Episode 60, Total Reward: -8.30, Win Rate: 1.64%\n",
      "Episode 70, Total Reward: -8.51, Win Rate: 4.23%\n",
      "Episode 80, Total Reward: -10.17, Win Rate: 3.70%\n",
      "Episode 90, Total Reward: -12.02, Win Rate: 4.40%\n",
      "Episode 100, Total Reward: -9.01, Win Rate: 5.00%\n",
      "Episode 110, Total Reward: -10.01, Win Rate: 6.00%\n",
      "Episode 120, Total Reward: -10.53, Win Rate: 7.00%\n",
      "Episode 130, Total Reward: -8.46, Win Rate: 7.00%\n",
      "Episode 140, Total Reward: -10.64, Win Rate: 8.00%\n",
      "Episode 150, Total Reward: -10.05, Win Rate: 10.00%\n",
      "Episode 160, Total Reward: -10.76, Win Rate: 10.00%\n",
      "Episode 170, Total Reward: -9.84, Win Rate: 8.00%\n",
      "Episode 180, Total Reward: -10.94, Win Rate: 9.00%\n",
      "Episode 190, Total Reward: -10.36, Win Rate: 9.00%\n",
      "Episode 200, Total Reward: -10.82, Win Rate: 8.00%\n",
      "Episode 210, Total Reward: -10.56, Win Rate: 9.00%\n",
      "Episode 220, Total Reward: -8.38, Win Rate: 9.00%\n",
      "Episode 230, Total Reward: -8.60, Win Rate: 9.00%\n",
      "Episode 240, Total Reward: -7.85, Win Rate: 8.00%\n",
      "Episode 250, Total Reward: -10.53, Win Rate: 7.00%\n",
      "Episode 260, Total Reward: -10.97, Win Rate: 7.00%\n",
      "Episode 270, Total Reward: -9.13, Win Rate: 8.00%\n",
      "Episode 280, Total Reward: -7.76, Win Rate: 7.00%\n",
      "Episode 290, Total Reward: -7.79, Win Rate: 6.00%\n",
      "Episode 300, Total Reward: -8.58, Win Rate: 7.00%\n",
      "Episode 310, Total Reward: -8.62, Win Rate: 6.00%\n",
      "Episode 320, Total Reward: -8.48, Win Rate: 5.00%\n",
      "Episode 330, Total Reward: -9.02, Win Rate: 5.00%\n",
      "Episode 340, Total Reward: -7.57, Win Rate: 9.00%\n",
      "Episode 350, Total Reward: -8.20, Win Rate: 9.00%\n",
      "Episode 360, Total Reward: -10.89, Win Rate: 8.00%\n",
      "Episode 370, Total Reward: -9.45, Win Rate: 7.00%\n",
      "Episode 380, Total Reward: -10.12, Win Rate: 7.00%\n",
      "Episode 390, Total Reward: -9.34, Win Rate: 7.00%\n",
      "Episode 400, Total Reward: -7.18, Win Rate: 7.00%\n",
      "Episode 410, Total Reward: -9.37, Win Rate: 6.00%\n",
      "Episode 420, Total Reward: -10.83, Win Rate: 8.00%\n",
      "Episode 430, Total Reward: 13.54, Win Rate: 10.00%\n",
      "Episode 440, Total Reward: -10.67, Win Rate: 10.00%\n",
      "Episode 450, Total Reward: -10.93, Win Rate: 10.00%\n",
      "Episode 460, Total Reward: -11.53, Win Rate: 11.00%\n",
      "Episode 470, Total Reward: -8.45, Win Rate: 12.00%\n",
      "Episode 480, Total Reward: -10.06, Win Rate: 12.00%\n",
      "Episode 490, Total Reward: -10.09, Win Rate: 14.00%\n",
      "Episode 500, Total Reward: -8.13, Win Rate: 14.00%\n",
      "Episode 510, Total Reward: -8.71, Win Rate: 15.00%\n",
      "Episode 520, Total Reward: -8.23, Win Rate: 16.00%\n",
      "Episode 530, Total Reward: -6.60, Win Rate: 15.00%\n",
      "Episode 540, Total Reward: -12.13, Win Rate: 13.00%\n",
      "Episode 550, Total Reward: -8.90, Win Rate: 12.00%\n",
      "Episode 560, Total Reward: -9.84, Win Rate: 12.00%\n",
      "Episode 570, Total Reward: -11.42, Win Rate: 13.00%\n",
      "Episode 580, Total Reward: -8.82, Win Rate: 14.00%\n",
      "Episode 590, Total Reward: -9.99, Win Rate: 15.00%\n",
      "Episode 600, Total Reward: 14.11, Win Rate: 16.00%\n",
      "Episode 610, Total Reward: 13.20, Win Rate: 16.00%\n",
      "Episode 620, Total Reward: 13.15, Win Rate: 18.00%\n",
      "Episode 630, Total Reward: -10.34, Win Rate: 19.00%\n",
      "Episode 640, Total Reward: -10.47, Win Rate: 19.00%\n",
      "Episode 650, Total Reward: -8.72, Win Rate: 22.00%\n",
      "Episode 660, Total Reward: -7.64, Win Rate: 22.00%\n",
      "Episode 670, Total Reward: -8.66, Win Rate: 23.00%\n",
      "Episode 680, Total Reward: -8.54, Win Rate: 23.00%\n",
      "Episode 690, Total Reward: 13.52, Win Rate: 23.00%\n",
      "Episode 700, Total Reward: 17.60, Win Rate: 25.00%\n",
      "Episode 710, Total Reward: -8.66, Win Rate: 25.00%\n",
      "Episode 720, Total Reward: -8.80, Win Rate: 20.00%\n",
      "Episode 730, Total Reward: -8.09, Win Rate: 19.00%\n",
      "Episode 740, Total Reward: -9.02, Win Rate: 22.00%\n",
      "Episode 750, Total Reward: -8.86, Win Rate: 20.00%\n",
      "Episode 760, Total Reward: -8.49, Win Rate: 20.00%\n",
      "Episode 770, Total Reward: -10.93, Win Rate: 17.00%\n",
      "Episode 780, Total Reward: -7.77, Win Rate: 17.00%\n",
      "Episode 790, Total Reward: -8.40, Win Rate: 15.00%\n",
      "Episode 800, Total Reward: -7.60, Win Rate: 14.00%\n",
      "Episode 810, Total Reward: -9.55, Win Rate: 17.00%\n",
      "Episode 820, Total Reward: -8.55, Win Rate: 19.00%\n",
      "Episode 830, Total Reward: 17.39, Win Rate: 19.00%\n",
      "Episode 840, Total Reward: -8.24, Win Rate: 15.00%\n",
      "Episode 850, Total Reward: -8.06, Win Rate: 18.00%\n",
      "Episode 860, Total Reward: -8.19, Win Rate: 18.00%\n",
      "Episode 870, Total Reward: -9.13, Win Rate: 19.00%\n",
      "Episode 880, Total Reward: 14.95, Win Rate: 22.00%\n",
      "Episode 890, Total Reward: -7.63, Win Rate: 21.00%\n",
      "Episode 900, Total Reward: -8.31, Win Rate: 20.00%\n",
      "Episode 910, Total Reward: -9.55, Win Rate: 17.00%\n",
      "Episode 920, Total Reward: -8.48, Win Rate: 17.00%\n",
      "Episode 930, Total Reward: -7.97, Win Rate: 19.00%\n",
      "Episode 940, Total Reward: -8.43, Win Rate: 19.00%\n",
      "Episode 950, Total Reward: -7.03, Win Rate: 17.00%\n",
      "Episode 960, Total Reward: -9.82, Win Rate: 17.00%\n",
      "Episode 970, Total Reward: -10.59, Win Rate: 19.00%\n",
      "Episode 980, Total Reward: 17.94, Win Rate: 17.00%\n",
      "Episode 990, Total Reward: -10.94, Win Rate: 19.00%\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "from rl import PokemonEnv, DQNAgent, create_pokemon_teams\n",
    "\n",
    "# Create environment\n",
    "env = PokemonEnv(create_pokemon_teams)\n",
    "# Initialize DQN agent\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# Training hyperparameters\n",
    "agent = DQNAgent(\n",
    "    state_size=state_size,\n",
    "    action_size=action_size,\n",
    "    gamma=0.99,  # discount factor\n",
    "    epsilon=1.0,\n",
    "    epsilon_min=0.05,\n",
    "    epsilon_decay=0.9999,\n",
    "    learning_rate=0.0003,\n",
    "    batch_size=128,\n",
    "    buffer_size=200000,\n",
    "    update_target_freq=1000,\n",
    "    use_dueling=True,\n",
    "    grad_clip_norm=10.0\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "n_episodes = 1000\n",
    "for episode in range(n_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # 행동 선택\n",
    "        action = agent.choose_action(state, env.get_valid_actions())\n",
    "        \n",
    "        # 환경과 상호작용\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # 경험 저장\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        # 상태 업데이트\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        # 배치 학습 수행\n",
    "        loss = agent.train_batch()\n",
    "        \n",
    "    # 에피소드 결과 기록\n",
    "    if done:\n",
    "        if terminated:  # 승리/패배로 종료된 경우\n",
    "            if reward > 0:\n",
    "                agent.add_win()\n",
    "            else:\n",
    "                agent.add_loss()\n",
    "    \n",
    "    # 진행상황 출력\n",
    "    if episode % 10 == 0:\n",
    "        win_rate = agent.get_recent_win_rate()\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}%\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
